# TODO: vlm path only, works with `scripts/llama-serve.sh`, assume openai api `http://127.0.0.1:8080`
